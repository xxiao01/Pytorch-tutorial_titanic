{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Moran, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330877</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17463</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>E46</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Palsson, Master. Gosta Leonard</td>\n",
       "      <td>male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>349909</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>347742</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>237736</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "5            6         0       3   \n",
       "6            7         0       1   \n",
       "7            8         0       3   \n",
       "8            9         1       3   \n",
       "9           10         1       2   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "5                                   Moran, Mr. James    male   NaN      0   \n",
       "6                            McCarthy, Mr. Timothy J    male  54.0      0   \n",
       "7                     Palsson, Master. Gosta Leonard    male   2.0      3   \n",
       "8  Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  female  27.0      0   \n",
       "9                Nasser, Mrs. Nicholas (Adele Achem)  female  14.0      1   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  \n",
       "5      0            330877   8.4583   NaN        Q  \n",
       "6      0             17463  51.8625   E46        S  \n",
       "7      1            349909  21.0750   NaN        S  \n",
       "8      2            347742  11.1333   NaN        S  \n",
       "9      0            237736  30.0708   NaN        C  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('train.csv')\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[~data['Age'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = data.drop(columns = ['PassengerId', 'Name', 'Ticket'])\n",
    "label = data['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass     Sex   Age  SibSp  Parch     Fare Cabin Embarked\n",
       "0         0       3    male  22.0      1      0   7.2500   NaN        S\n",
       "1         1       1  female  38.0      1      0  71.2833   C85        C\n",
       "2         1       3  female  26.0      0      0   7.9250   NaN        S\n",
       "3         1       1  female  35.0      1      0  53.1000  C123        S\n",
       "4         0       3    male  35.0      0      0   8.0500   NaN        S"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_onehot = pd.get_dummies(feature[['Sex', 'Pclass', 'Embarked']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>885</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>29.1250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>886</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>887</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>889</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>714 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass     Sex   Age  SibSp  Parch     Fare Cabin Embarked  \\\n",
       "0           0       3    male  22.0      1      0   7.2500   NaN        S   \n",
       "1           1       1  female  38.0      1      0  71.2833   C85        C   \n",
       "2           1       3  female  26.0      0      0   7.9250   NaN        S   \n",
       "3           1       1  female  35.0      1      0  53.1000  C123        S   \n",
       "4           0       3    male  35.0      0      0   8.0500   NaN        S   \n",
       "..        ...     ...     ...   ...    ...    ...      ...   ...      ...   \n",
       "885         0       3  female  39.0      0      5  29.1250   NaN        Q   \n",
       "886         0       2    male  27.0      0      0  13.0000   NaN        S   \n",
       "887         1       1  female  19.0      0      0  30.0000   B42        S   \n",
       "889         1       1    male  26.0      0      0  30.0000  C148        C   \n",
       "890         0       3    male  32.0      0      0   7.7500   NaN        Q   \n",
       "\n",
       "     Pclass  Sex_female  Sex_male  Embarked_C  Embarked_Q  Embarked_S  \n",
       "0         3           0         1           0           0           1  \n",
       "1         1           1         0           1           0           0  \n",
       "2         3           1         0           0           0           1  \n",
       "3         1           1         0           0           0           1  \n",
       "4         3           0         1           0           0           1  \n",
       "..      ...         ...       ...         ...         ...         ...  \n",
       "885       3           1         0           0           1           0  \n",
       "886       2           0         1           0           0           1  \n",
       "887       1           1         0           0           0           1  \n",
       "889       1           0         1           1           0           0  \n",
       "890       3           0         1           0           1           0  \n",
       "\n",
       "[714 rows x 15 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_f = pd.concat([feature, df_onehot], axis=1)\n",
    "df_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived   Age  SibSp  Parch     Fare  Sex_female  Sex_male  Embarked_C  \\\n",
       "0         0  22.0      1      0   7.2500           0         1           0   \n",
       "1         1  38.0      1      0  71.2833           1         0           1   \n",
       "2         1  26.0      0      0   7.9250           1         0           0   \n",
       "3         1  35.0      1      0  53.1000           1         0           0   \n",
       "4         0  35.0      0      0   8.0500           0         1           0   \n",
       "\n",
       "   Embarked_Q  Embarked_S  \n",
       "0           0           1  \n",
       "1           0           0  \n",
       "2           0           1  \n",
       "3           0           1  \n",
       "4           0           1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_f = df_f.drop(columns = ['Sex', 'Pclass', 'Embarked', 'Cabin'])\n",
    "df_f.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 714 entries, 0 to 890\n",
      "Data columns (total 10 columns):\n",
      "Survived      714 non-null int64\n",
      "Age           714 non-null float64\n",
      "SibSp         714 non-null int64\n",
      "Parch         714 non-null int64\n",
      "Fare          714 non-null float64\n",
      "Sex_female    714 non-null uint8\n",
      "Sex_male      714 non-null uint8\n",
      "Embarked_C    714 non-null uint8\n",
      "Embarked_Q    714 non-null uint8\n",
      "Embarked_S    714 non-null uint8\n",
      "dtypes: float64(2), int64(3), uint8(5)\n",
      "memory usage: 37.0 KB\n"
     ]
    }
   ],
   "source": [
    "df_f.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>885</td>\n",
       "      <td>0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>29.1250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>886</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>887</td>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>889</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>714 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived   Age  SibSp  Parch     Fare  Sex_female  Sex_male  Embarked_C  \\\n",
       "0           0  22.0      1      0   7.2500           0         1           0   \n",
       "1           1  38.0      1      0  71.2833           1         0           1   \n",
       "2           1  26.0      0      0   7.9250           1         0           0   \n",
       "3           1  35.0      1      0  53.1000           1         0           0   \n",
       "4           0  35.0      0      0   8.0500           0         1           0   \n",
       "..        ...   ...    ...    ...      ...         ...       ...         ...   \n",
       "885         0  39.0      0      5  29.1250           1         0           0   \n",
       "886         0  27.0      0      0  13.0000           0         1           0   \n",
       "887         1  19.0      0      0  30.0000           1         0           0   \n",
       "889         1  26.0      0      0  30.0000           0         1           1   \n",
       "890         0  32.0      0      0   7.7500           0         1           0   \n",
       "\n",
       "     Embarked_Q  Embarked_S  \n",
       "0             0           1  \n",
       "1             0           0  \n",
       "2             0           1  \n",
       "3             0           1  \n",
       "4             0           1  \n",
       "..          ...         ...  \n",
       "885           1           0  \n",
       "886           0           1  \n",
       "887           0           1  \n",
       "889           0           0  \n",
       "890           1           0  \n",
       "\n",
       "[714 rows x 10 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_f.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 714 entries, 0 to 890\n",
      "Data columns (total 10 columns):\n",
      "Survived      714 non-null int64\n",
      "Age           714 non-null float64\n",
      "SibSp         714 non-null int64\n",
      "Parch         714 non-null int64\n",
      "Fare          714 non-null float64\n",
      "Sex_female    714 non-null uint8\n",
      "Sex_male      714 non-null uint8\n",
      "Embarked_C    714 non-null uint8\n",
      "Embarked_Q    714 non-null uint8\n",
      "Embarked_S    714 non-null uint8\n",
      "dtypes: float64(2), int64(3), uint8(5)\n",
      "memory usage: 37.0 KB\n"
     ]
    }
   ],
   "source": [
    "df_f.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change df_f and label to tensor formate for pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "714\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[22.,  1.,  0., ...,  0.,  0.,  1.],\n",
       "       [38.,  1.,  0., ...,  1.,  0.,  0.],\n",
       "       [26.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "       ...,\n",
       "       [19.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "       [26.,  0.,  0., ...,  1.,  0.,  0.],\n",
       "       [32.,  0.,  0., ...,  0.,  1.,  0.]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_f.values[:,1:].astype('float32')\n",
    "print(len(X))\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "714\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df_f.values[:, 0].astype('float32')\n",
    "y = y.reshape(len(y), 1)\n",
    "print(len(y))\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split the data into train and test sets\n",
    "# this lets us simulate how our model will perform in the future\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "N, D = X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N:  478\n",
      "D:  9\n"
     ]
    }
   ],
   "source": [
    "print('N: ', N)\n",
    "print('D: ', D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "# you'll learn why scaling is needed in a later course\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.40470913,  0.5690679 ,  1.9724817 ,  0.68905216,  1.3460181 ,\n",
       "       -1.3460181 , -0.49148595, -0.21964884,  0.56929755], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now all the fun PyTorch stuff\n",
    "# Build the model\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(D, 3),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(3, 1),\n",
    "    nn.Sigmoid()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data into torch tensors\n",
    "X_train = torch.from_numpy(X_train.astype(np.float32))\n",
    "X_test = torch.from_numpy(X_test.astype(np.float32))\n",
    "y_train = torch.from_numpy(y_train.astype(np.float32).reshape(-1, 1))\n",
    "y_test = torch.from_numpy(y_test.astype(np.float32).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/5000, Train Loss: 0.7236, Test Loss: 0.7052\n",
      "Epoch 100/5000, Train Loss: 0.6942, Test Loss: 0.6861\n",
      "Epoch 150/5000, Train Loss: 0.6717, Test Loss: 0.6727\n",
      "Epoch 200/5000, Train Loss: 0.6542, Test Loss: 0.6630\n",
      "Epoch 250/5000, Train Loss: 0.6401, Test Loss: 0.6557\n",
      "Epoch 300/5000, Train Loss: 0.6280, Test Loss: 0.6494\n",
      "Epoch 350/5000, Train Loss: 0.6170, Test Loss: 0.6434\n",
      "Epoch 400/5000, Train Loss: 0.6068, Test Loss: 0.6371\n",
      "Epoch 450/5000, Train Loss: 0.5970, Test Loss: 0.6303\n",
      "Epoch 500/5000, Train Loss: 0.5876, Test Loss: 0.6231\n",
      "Epoch 550/5000, Train Loss: 0.5784, Test Loss: 0.6155\n",
      "Epoch 600/5000, Train Loss: 0.5696, Test Loss: 0.6080\n",
      "Epoch 650/5000, Train Loss: 0.5611, Test Loss: 0.6005\n",
      "Epoch 700/5000, Train Loss: 0.5530, Test Loss: 0.5933\n",
      "Epoch 750/5000, Train Loss: 0.5454, Test Loss: 0.5864\n",
      "Epoch 800/5000, Train Loss: 0.5381, Test Loss: 0.5799\n",
      "Epoch 850/5000, Train Loss: 0.5314, Test Loss: 0.5738\n",
      "Epoch 900/5000, Train Loss: 0.5250, Test Loss: 0.5681\n",
      "Epoch 950/5000, Train Loss: 0.5191, Test Loss: 0.5627\n",
      "Epoch 1000/5000, Train Loss: 0.5135, Test Loss: 0.5577\n",
      "Epoch 1050/5000, Train Loss: 0.5084, Test Loss: 0.5529\n",
      "Epoch 1100/5000, Train Loss: 0.5036, Test Loss: 0.5485\n",
      "Epoch 1150/5000, Train Loss: 0.4991, Test Loss: 0.5444\n",
      "Epoch 1200/5000, Train Loss: 0.4950, Test Loss: 0.5408\n",
      "Epoch 1250/5000, Train Loss: 0.4913, Test Loss: 0.5376\n",
      "Epoch 1300/5000, Train Loss: 0.4880, Test Loss: 0.5348\n",
      "Epoch 1350/5000, Train Loss: 0.4850, Test Loss: 0.5326\n",
      "Epoch 1400/5000, Train Loss: 0.4823, Test Loss: 0.5307\n",
      "Epoch 1450/5000, Train Loss: 0.4800, Test Loss: 0.5291\n",
      "Epoch 1500/5000, Train Loss: 0.4779, Test Loss: 0.5279\n",
      "Epoch 1550/5000, Train Loss: 0.4761, Test Loss: 0.5269\n",
      "Epoch 1600/5000, Train Loss: 0.4745, Test Loss: 0.5262\n",
      "Epoch 1650/5000, Train Loss: 0.4731, Test Loss: 0.5257\n",
      "Epoch 1700/5000, Train Loss: 0.4718, Test Loss: 0.5254\n",
      "Epoch 1750/5000, Train Loss: 0.4706, Test Loss: 0.5252\n",
      "Epoch 1800/5000, Train Loss: 0.4695, Test Loss: 0.5252\n",
      "Epoch 1850/5000, Train Loss: 0.4684, Test Loss: 0.5253\n",
      "Epoch 1900/5000, Train Loss: 0.4674, Test Loss: 0.5255\n",
      "Epoch 1950/5000, Train Loss: 0.4664, Test Loss: 0.5258\n",
      "Epoch 2000/5000, Train Loss: 0.4654, Test Loss: 0.5261\n",
      "Epoch 2050/5000, Train Loss: 0.4644, Test Loss: 0.5264\n",
      "Epoch 2100/5000, Train Loss: 0.4635, Test Loss: 0.5267\n",
      "Epoch 2150/5000, Train Loss: 0.4625, Test Loss: 0.5269\n",
      "Epoch 2200/5000, Train Loss: 0.4616, Test Loss: 0.5271\n",
      "Epoch 2250/5000, Train Loss: 0.4608, Test Loss: 0.5271\n",
      "Epoch 2300/5000, Train Loss: 0.4599, Test Loss: 0.5271\n",
      "Epoch 2350/5000, Train Loss: 0.4591, Test Loss: 0.5270\n",
      "Epoch 2400/5000, Train Loss: 0.4583, Test Loss: 0.5269\n",
      "Epoch 2450/5000, Train Loss: 0.4576, Test Loss: 0.5267\n",
      "Epoch 2500/5000, Train Loss: 0.4568, Test Loss: 0.5265\n",
      "Epoch 2550/5000, Train Loss: 0.4560, Test Loss: 0.5261\n",
      "Epoch 2600/5000, Train Loss: 0.4551, Test Loss: 0.5257\n",
      "Epoch 2650/5000, Train Loss: 0.4543, Test Loss: 0.5252\n",
      "Epoch 2700/5000, Train Loss: 0.4535, Test Loss: 0.5247\n",
      "Epoch 2750/5000, Train Loss: 0.4527, Test Loss: 0.5243\n",
      "Epoch 2800/5000, Train Loss: 0.4519, Test Loss: 0.5239\n",
      "Epoch 2850/5000, Train Loss: 0.4511, Test Loss: 0.5235\n",
      "Epoch 2900/5000, Train Loss: 0.4504, Test Loss: 0.5231\n",
      "Epoch 2950/5000, Train Loss: 0.4496, Test Loss: 0.5226\n",
      "Epoch 3000/5000, Train Loss: 0.4489, Test Loss: 0.5220\n",
      "Epoch 3050/5000, Train Loss: 0.4480, Test Loss: 0.5212\n",
      "Epoch 3100/5000, Train Loss: 0.4470, Test Loss: 0.5201\n",
      "Epoch 3150/5000, Train Loss: 0.4458, Test Loss: 0.5189\n",
      "Epoch 3200/5000, Train Loss: 0.4446, Test Loss: 0.5180\n",
      "Epoch 3250/5000, Train Loss: 0.4434, Test Loss: 0.5173\n",
      "Epoch 3300/5000, Train Loss: 0.4422, Test Loss: 0.5165\n",
      "Epoch 3350/5000, Train Loss: 0.4409, Test Loss: 0.5157\n",
      "Epoch 3400/5000, Train Loss: 0.4395, Test Loss: 0.5148\n",
      "Epoch 3450/5000, Train Loss: 0.4378, Test Loss: 0.5139\n",
      "Epoch 3500/5000, Train Loss: 0.4359, Test Loss: 0.5131\n",
      "Epoch 3550/5000, Train Loss: 0.4336, Test Loss: 0.5124\n",
      "Epoch 3600/5000, Train Loss: 0.4314, Test Loss: 0.5122\n",
      "Epoch 3650/5000, Train Loss: 0.4294, Test Loss: 0.5124\n",
      "Epoch 3700/5000, Train Loss: 0.4277, Test Loss: 0.5124\n",
      "Epoch 3750/5000, Train Loss: 0.4260, Test Loss: 0.5124\n",
      "Epoch 3800/5000, Train Loss: 0.4244, Test Loss: 0.5123\n",
      "Epoch 3850/5000, Train Loss: 0.4229, Test Loss: 0.5122\n",
      "Epoch 3900/5000, Train Loss: 0.4214, Test Loss: 0.5121\n",
      "Epoch 3950/5000, Train Loss: 0.4201, Test Loss: 0.5121\n",
      "Epoch 4000/5000, Train Loss: 0.4187, Test Loss: 0.5120\n",
      "Epoch 4050/5000, Train Loss: 0.4175, Test Loss: 0.5120\n",
      "Epoch 4100/5000, Train Loss: 0.4163, Test Loss: 0.5121\n",
      "Epoch 4150/5000, Train Loss: 0.4151, Test Loss: 0.5122\n",
      "Epoch 4200/5000, Train Loss: 0.4140, Test Loss: 0.5124\n",
      "Epoch 4250/5000, Train Loss: 0.4129, Test Loss: 0.5126\n",
      "Epoch 4300/5000, Train Loss: 0.4119, Test Loss: 0.5128\n",
      "Epoch 4350/5000, Train Loss: 0.4109, Test Loss: 0.5131\n",
      "Epoch 4400/5000, Train Loss: 0.4099, Test Loss: 0.5134\n",
      "Epoch 4450/5000, Train Loss: 0.4090, Test Loss: 0.5137\n",
      "Epoch 4500/5000, Train Loss: 0.4081, Test Loss: 0.5140\n",
      "Epoch 4550/5000, Train Loss: 0.4073, Test Loss: 0.5143\n",
      "Epoch 4600/5000, Train Loss: 0.4064, Test Loss: 0.5146\n",
      "Epoch 4650/5000, Train Loss: 0.4056, Test Loss: 0.5149\n",
      "Epoch 4700/5000, Train Loss: 0.4048, Test Loss: 0.5152\n",
      "Epoch 4750/5000, Train Loss: 0.4041, Test Loss: 0.5154\n",
      "Epoch 4800/5000, Train Loss: 0.4033, Test Loss: 0.5155\n",
      "Epoch 4850/5000, Train Loss: 0.4026, Test Loss: 0.5156\n",
      "Epoch 4900/5000, Train Loss: 0.4018, Test Loss: 0.5157\n",
      "Epoch 4950/5000, Train Loss: 0.4008, Test Loss: 0.5153\n",
      "Epoch 5000/5000, Train Loss: 0.3991, Test Loss: 0.5140\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "n_epochs = 5000\n",
    "\n",
    "# Stuff to store\n",
    "train_losses = np.zeros(n_epochs)\n",
    "test_losses = np.zeros(n_epochs)\n",
    "\n",
    "# lr = 1e-5\n",
    "\n",
    "for it in range(n_epochs):\n",
    "  # zero the parameter gradients\n",
    "  optimizer.zero_grad()\n",
    "\n",
    "  # Forward pass\n",
    "  outputs = model(X_train)\n",
    "  loss = criterion(outputs, y_train)\n",
    "    \n",
    "  # Backward and optimize\n",
    "  loss.backward()\n",
    "  optimizer.step()\n",
    "\n",
    "  # Get test loss\n",
    "  outputs_test = model(X_test)\n",
    "  loss_test = criterion(outputs_test, y_test)\n",
    "\n",
    "  # Save losses\n",
    "  train_losses[it] = loss.item()\n",
    "  test_losses[it] = loss_test.item()\n",
    "    \n",
    "  if (it + 1) % 50 == 0:\n",
    "    print(f'Epoch {it+1}/{n_epochs}, Train Loss: {loss.item():.4f}, Test Loss: {loss_test.item():.4f}')\n",
    "\n",
    "#   with torch.no_grad():\n",
    "#     for param in model.parameters():\n",
    "#         param -= lr * param.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the train loss and test loss per iteration\n",
    "plt.plot(train_losses, label='train loss')\n",
    "plt.plot(test_losses, label='test loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  tensor([ 2.1141, -0.3073])\n",
      "tensor([0.8923, 0.4238])\n"
     ]
    }
   ],
   "source": [
    "m = nn.Sigmoid()\n",
    "input = torch.randn(2)\n",
    "output = m(input)\n",
    "print('Input: ', input)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'weight'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-72b20984609d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    592\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 594\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'weight'"
     ]
    }
   ],
   "source": [
    "print(model.weight.shape)\n",
    "model.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
